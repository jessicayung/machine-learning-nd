{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Methodology: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_names = ['Symbol',\n",
    " 'Date',\n",
    " 'Open',\n",
    " 'High',\n",
    " 'Low',\n",
    " 'Close',\n",
    " 'Volume',\n",
    " 'Ex-Dividend',\n",
    " 'Split Ratio',\n",
    " 'Adj. Open',\n",
    " 'Adj. High',\n",
    " 'Adj. Low',\n",
    " 'Adj. Close',\n",
    " 'Adj. Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read HUGE csv that has all the daily LSE data from 1977\n",
    "# Data Preprocessing: adding header to CSV\n",
    "df = pd.read_csv('~/lse-data/lse/WIKI_20160909.csv', header=None, names=header_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Examining Abnormalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to investigate previous observation that Opening, High, Low, Close prices have minimum of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Adj. Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1047193</th>\n",
       "      <td>ARWR</td>\n",
       "      <td>2002-10-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047194</th>\n",
       "      <td>ARWR</td>\n",
       "      <td>2002-10-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047195</th>\n",
       "      <td>ARWR</td>\n",
       "      <td>2002-10-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047196</th>\n",
       "      <td>ARWR</td>\n",
       "      <td>2002-10-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047197</th>\n",
       "      <td>ARWR</td>\n",
       "      <td>2002-10-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047198</th>\n",
       "      <td>ARWR</td>\n",
       "      <td>2002-10-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047199</th>\n",
       "      <td>ARWR</td>\n",
       "      <td>2002-10-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047200</th>\n",
       "      <td>ARWR</td>\n",
       "      <td>2002-10-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608936</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-02-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>57.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608983</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-04-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608984</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608985</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-05-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608986</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-05-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608987</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-05-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608988</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-05-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608989</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-05-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608990</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-05-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608991</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-05-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608992</th>\n",
       "      <td>LFVN</td>\n",
       "      <td>2003-05-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330994</th>\n",
       "      <td>NUTR</td>\n",
       "      <td>2008-09-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.426355</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614062</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614063</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-01-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614064</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-01-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614065</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-01-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614066</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614067</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614068</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-02-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614069</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-02-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614070</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-02-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614071</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-02-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614242</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614243</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614244</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614245</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614246</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614247</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614248</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614249</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614250</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614251</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614252</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614253</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614254</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614255</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614256</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614257</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614258</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614259</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614260</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614261</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614262</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614263</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614264</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614265</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614266</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614267</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614268</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614269</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614270</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13614271</th>\n",
       "      <td>VTNR</td>\n",
       "      <td>2002-11-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Symbol        Date  Open  High  Low  Close   Volume  Ex-Dividend  \\\n",
       "1047193    ARWR  2002-10-11   0.0  0.00  0.0   0.00  65000.0          0.0   \n",
       "1047194    ARWR  2002-10-14   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "1047195    ARWR  2002-10-15   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "1047196    ARWR  2002-10-16   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "1047197    ARWR  2002-10-17   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "1047198    ARWR  2002-10-18   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "1047199    ARWR  2002-10-21   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "1047200    ARWR  2002-10-22   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "7608936    LFVN  2003-02-21   0.0  0.01  0.0   0.01  27200.0          0.0   \n",
       "7608983    LFVN  2003-04-30   0.0  0.00  0.0   0.00   6800.0          0.0   \n",
       "7608984    LFVN  2003-05-01   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "7608985    LFVN  2003-05-02   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "7608986    LFVN  2003-05-05   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "7608987    LFVN  2003-05-06   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "7608988    LFVN  2003-05-07   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "7608989    LFVN  2003-05-08   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "7608990    LFVN  2003-05-09   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "7608991    LFVN  2003-05-12   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "7608992    LFVN  2003-05-13   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "9330994    NUTR  2008-09-12   0.0  0.00  0.0  12.15      0.0          0.0   \n",
       "13614062   VTNR  2002-01-25   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614063   VTNR  2002-01-28   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614064   VTNR  2002-01-29   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614065   VTNR  2002-01-30   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614066   VTNR  2002-01-31   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614067   VTNR  2002-02-01   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614068   VTNR  2002-02-04   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614069   VTNR  2002-02-05   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614070   VTNR  2002-02-06   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614071   VTNR  2002-02-07   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "...         ...         ...   ...   ...  ...    ...      ...          ...   \n",
       "13614242   VTNR  2002-10-11   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614243   VTNR  2002-10-14   0.0  0.00  0.0   0.00  48000.0          0.0   \n",
       "13614244   VTNR  2002-10-15   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614245   VTNR  2002-10-16   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614246   VTNR  2002-10-17   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614247   VTNR  2002-10-18   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614248   VTNR  2002-10-21   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614249   VTNR  2002-10-22   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614250   VTNR  2002-10-23   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614251   VTNR  2002-10-24   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614252   VTNR  2002-10-25   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614253   VTNR  2002-10-28   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614254   VTNR  2002-10-29   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614255   VTNR  2002-10-30   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614256   VTNR  2002-10-31   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614257   VTNR  2002-11-01   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614258   VTNR  2002-11-04   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614259   VTNR  2002-11-05   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614260   VTNR  2002-11-06   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614261   VTNR  2002-11-07   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614262   VTNR  2002-11-08   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614263   VTNR  2002-11-11   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614264   VTNR  2002-11-12   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614265   VTNR  2002-11-13   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614266   VTNR  2002-11-14   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614267   VTNR  2002-11-15   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614268   VTNR  2002-11-18   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614269   VTNR  2002-11-19   0.0  0.00  0.0   0.00      0.0          0.0   \n",
       "13614270   VTNR  2002-11-20   0.0  0.00  0.0   0.00  24000.0          0.0   \n",
       "13614271   VTNR  2002-11-21   0.0  0.02  0.0   0.02  24000.0          0.0   \n",
       "\n",
       "          Split Ratio  Adj. Open  Adj. High  Adj. Low  Adj. Close  Adj. Volume  \n",
       "1047193           1.0        0.0       0.00       0.0    0.000000   100.000000  \n",
       "1047194           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "1047195           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "1047196           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "1047197           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "1047198           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "1047199           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "1047200           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "7608936           1.0        0.0       4.76       0.0    4.760000    57.142857  \n",
       "7608983           1.0        0.0       0.00       0.0    0.000000    14.285714  \n",
       "7608984           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "7608985           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "7608986           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "7608987           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "7608988           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "7608989           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "7608990           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "7608991           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "7608992           1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "9330994           1.0        0.0       0.00       0.0   11.426355     0.000000  \n",
       "13614062          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614063          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614064          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614065          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614066          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614067          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614068          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614069          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614070          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614071          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "...               ...        ...        ...       ...         ...          ...  \n",
       "13614242          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614243          1.0        0.0       0.00       0.0    0.000000   800.000000  \n",
       "13614244          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614245          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614246          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614247          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614248          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614249          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614250          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614251          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614252          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614253          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614254          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614255          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614256          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614257          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614258          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614259          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614260          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614261          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614262          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614263          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614264          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614265          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614266          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614267          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614268          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614269          1.0        0.0       0.00       0.0    0.000000     0.000000  \n",
       "13614270          1.0        0.0       0.00       0.0    0.000000   400.000000  \n",
       "13614271          1.0        0.0       1.20       0.0    1.200000   400.000000  \n",
       "\n",
       "[225 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Open'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Measures of variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "# These features are not used in the current model but are nice for visualisations\n",
    "df.loc[:,'Daily Variation'] = df.loc[:,'High'] - df.loc[:,'Low']\n",
    "df.loc[:,'Percentage Variation'] = df.loc[:,'Daily Variation'] / df.loc[:,'Open'] * 100\n",
    "df.loc[:,'Adj. Daily Variation'] = df.loc[:,'Adj. High'] - df.loc[:,'Adj. Low']\n",
    "df.loc[:,'Adj. Percentage Variation'] = df.loc[:,'Adj. Daily Variation'] / df.loc[:,'Adj. Open'] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Extracting specific stocks\n",
    "#### 1.2.2.1 BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Adj. Volume</th>\n",
       "      <th>Daily Variation</th>\n",
       "      <th>Percentage Variation</th>\n",
       "      <th>Adj. Daily Variation</th>\n",
       "      <th>Adj. Percentage Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1923099</th>\n",
       "      <td>BP</td>\n",
       "      <td>1977-01-03</td>\n",
       "      <td>76.50</td>\n",
       "      <td>77.62</td>\n",
       "      <td>76.50</td>\n",
       "      <td>77.62</td>\n",
       "      <td>12400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.990787</td>\n",
       "      <td>2.019933</td>\n",
       "      <td>1.990787</td>\n",
       "      <td>2.019933</td>\n",
       "      <td>198400.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.464052</td>\n",
       "      <td>0.029146</td>\n",
       "      <td>1.464052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923100</th>\n",
       "      <td>BP</td>\n",
       "      <td>1977-01-04</td>\n",
       "      <td>77.62</td>\n",
       "      <td>78.00</td>\n",
       "      <td>76.75</td>\n",
       "      <td>77.00</td>\n",
       "      <td>19300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.019933</td>\n",
       "      <td>2.029822</td>\n",
       "      <td>1.997292</td>\n",
       "      <td>2.003798</td>\n",
       "      <td>308800.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.610410</td>\n",
       "      <td>0.032529</td>\n",
       "      <td>1.610410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923101</th>\n",
       "      <td>BP</td>\n",
       "      <td>1977-01-05</td>\n",
       "      <td>77.00</td>\n",
       "      <td>77.00</td>\n",
       "      <td>74.50</td>\n",
       "      <td>74.50</td>\n",
       "      <td>17900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.003798</td>\n",
       "      <td>2.003798</td>\n",
       "      <td>1.938740</td>\n",
       "      <td>1.938740</td>\n",
       "      <td>286400.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.246753</td>\n",
       "      <td>0.065058</td>\n",
       "      <td>3.246753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923102</th>\n",
       "      <td>BP</td>\n",
       "      <td>1977-01-06</td>\n",
       "      <td>74.50</td>\n",
       "      <td>75.50</td>\n",
       "      <td>74.50</td>\n",
       "      <td>75.12</td>\n",
       "      <td>23900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.938740</td>\n",
       "      <td>1.964763</td>\n",
       "      <td>1.938740</td>\n",
       "      <td>1.954874</td>\n",
       "      <td>382400.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.342282</td>\n",
       "      <td>0.026023</td>\n",
       "      <td>1.342282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923103</th>\n",
       "      <td>BP</td>\n",
       "      <td>1977-01-07</td>\n",
       "      <td>75.12</td>\n",
       "      <td>75.38</td>\n",
       "      <td>74.62</td>\n",
       "      <td>75.12</td>\n",
       "      <td>41700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.954874</td>\n",
       "      <td>1.961640</td>\n",
       "      <td>1.941863</td>\n",
       "      <td>1.954874</td>\n",
       "      <td>667200.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.011715</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>1.011715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbol        Date   Open   High    Low  Close   Volume  Ex-Dividend  \\\n",
       "1923099     BP  1977-01-03  76.50  77.62  76.50  77.62  12400.0          0.0   \n",
       "1923100     BP  1977-01-04  77.62  78.00  76.75  77.00  19300.0          0.0   \n",
       "1923101     BP  1977-01-05  77.00  77.00  74.50  74.50  17900.0          0.0   \n",
       "1923102     BP  1977-01-06  74.50  75.50  74.50  75.12  23900.0          0.0   \n",
       "1923103     BP  1977-01-07  75.12  75.38  74.62  75.12  41700.0          0.0   \n",
       "\n",
       "         Split Ratio  Adj. Open  Adj. High  Adj. Low  Adj. Close  Adj. Volume  \\\n",
       "1923099          1.0   1.990787   2.019933  1.990787    2.019933     198400.0   \n",
       "1923100          1.0   2.019933   2.029822  1.997292    2.003798     308800.0   \n",
       "1923101          1.0   2.003798   2.003798  1.938740    1.938740     286400.0   \n",
       "1923102          1.0   1.938740   1.964763  1.938740    1.954874     382400.0   \n",
       "1923103          1.0   1.954874   1.961640  1.941863    1.954874     667200.0   \n",
       "\n",
       "         Daily Variation  Percentage Variation  Adj. Daily Variation  \\\n",
       "1923099             1.12              1.464052              0.029146   \n",
       "1923100             1.25              1.610410              0.032529   \n",
       "1923101             2.50              3.246753              0.065058   \n",
       "1923102             1.00              1.342282              0.026023   \n",
       "1923103             0.76              1.011715              0.019778   \n",
       "\n",
       "         Adj. Percentage Variation  \n",
       "1923099                   1.464052  \n",
       "1923100                   1.610410  \n",
       "1923101                   3.246753  \n",
       "1923102                   1.342282  \n",
       "1923103                   1.011715  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract BP data\n",
    "bp = df[df['Symbol'] == 'BP']\n",
    "bp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2.2 Oil Stocks\n",
    "\n",
    "Found using the LSE stocks list (supplementary data source)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Company names and stock symbols\n",
    "China Petroleum and Chemical Corp: SNP,\n",
    "GAIL (India): GAIA or GAID,\n",
    "Gazprom: GAZ or 81jk or OGZD,\n",
    "Green Dragon Gas Ltd: GDG,\n",
    "Hellenic Petroleum SA: 98LQ or HLPD,\n",
    "Lukoil PJSC: LKOE, LKOD or LKOH,\n",
    "Magyar Olaj-es Gazipare Reszvenytar: MOLD,\n",
    "Mando Machinery Corp: MNMD or 05IS,\n",
    "Rosneft Oil Co: 40XT or ROSN,\n",
    "Royal Dutch Shell: RDSA or RDSB,\n",
    "Sacoil Hldgs Ltd: SAC,\n",
    "Surgutneftegaz: SGGD,\n",
    "Tatneft PJSC: ATAD,\n",
    "Total SA: TTA,\n",
    "Zoltav Resources Inc: ZOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oil stocks in DF:  ['GAIA']\n"
     ]
    }
   ],
   "source": [
    "# See which stocks are in our dataset:\n",
    "oil_stocks = [\"SNP\", \"GAIA\", \"GAID\", \"GAZ\", \"81JK\", \"OGZD\", \"GDG\", \"98LQ\", \"HLPD\", \n",
    "              \"LKOE\", \"LKOD\", \"LKOH\", \"MOLD\", \"MNMD\", \"05IS\", \"40XT\", \"ROSN\",\n",
    "             \"RDSA\", \"RDSB\", \"SAC\", \"SGGD\", \"ATAD\"]\n",
    "oil_stocks_in_df = []\n",
    "for stock in oil_stocks:\n",
    "    in_df = False\n",
    "    if not df[df['Symbol'] == stock].empty:\n",
    "        in_df = True\n",
    "        oil_stocks_in_df.append(stock)\n",
    "print \"Oil stocks in DF: \", oil_stocks_in_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Adj. Volume</th>\n",
       "      <th>Daily Variation</th>\n",
       "      <th>Percentage Variation</th>\n",
       "      <th>Adj. Daily Variation</th>\n",
       "      <th>Adj. Percentage Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5391755</th>\n",
       "      <td>GAIA</td>\n",
       "      <td>1999-10-29</td>\n",
       "      <td>5.50</td>\n",
       "      <td>8.62</td>\n",
       "      <td>5.38</td>\n",
       "      <td>6.38</td>\n",
       "      <td>895000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.303154</td>\n",
       "      <td>8.311489</td>\n",
       "      <td>5.187449</td>\n",
       "      <td>6.151659</td>\n",
       "      <td>895000.0</td>\n",
       "      <td>3.24</td>\n",
       "      <td>58.909091</td>\n",
       "      <td>3.124040</td>\n",
       "      <td>58.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391756</th>\n",
       "      <td>GAIA</td>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>6.62</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.88</td>\n",
       "      <td>144900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.383069</td>\n",
       "      <td>6.691617</td>\n",
       "      <td>6.267364</td>\n",
       "      <td>6.633764</td>\n",
       "      <td>144900.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>6.646526</td>\n",
       "      <td>0.424252</td>\n",
       "      <td>6.646526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391757</th>\n",
       "      <td>GAIA</td>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>6.91</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.62</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.662690</td>\n",
       "      <td>6.691617</td>\n",
       "      <td>6.267364</td>\n",
       "      <td>6.383069</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>6.367583</td>\n",
       "      <td>0.424252</td>\n",
       "      <td>6.367583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391758</th>\n",
       "      <td>GAIA</td>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.62</td>\n",
       "      <td>54500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.325217</td>\n",
       "      <td>6.508417</td>\n",
       "      <td>6.325217</td>\n",
       "      <td>6.383069</td>\n",
       "      <td>54500.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.896341</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>2.896341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391759</th>\n",
       "      <td>GAIA</td>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>6.62</td>\n",
       "      <td>6.69</td>\n",
       "      <td>6.56</td>\n",
       "      <td>6.56</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.383069</td>\n",
       "      <td>6.450564</td>\n",
       "      <td>6.325217</td>\n",
       "      <td>6.325217</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.963746</td>\n",
       "      <td>0.125347</td>\n",
       "      <td>1.963746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbol        Date  Open  High   Low  Close    Volume  Ex-Dividend  \\\n",
       "5391755   GAIA  1999-10-29  5.50  8.62  5.38   6.38  895000.0          0.0   \n",
       "5391756   GAIA  1999-11-01  6.62  6.94  6.50   6.88  144900.0          0.0   \n",
       "5391757   GAIA  1999-11-02  6.91  6.94  6.50   6.62  158000.0          0.0   \n",
       "5391758   GAIA  1999-11-03  6.56  6.75  6.56   6.62   54500.0          0.0   \n",
       "5391759   GAIA  1999-11-04  6.62  6.69  6.56   6.56   21000.0          0.0   \n",
       "\n",
       "         Split Ratio  Adj. Open  Adj. High  Adj. Low  Adj. Close  Adj. Volume  \\\n",
       "5391755          1.0   5.303154   8.311489  5.187449    6.151659     895000.0   \n",
       "5391756          1.0   6.383069   6.691617  6.267364    6.633764     144900.0   \n",
       "5391757          1.0   6.662690   6.691617  6.267364    6.383069     158000.0   \n",
       "5391758          1.0   6.325217   6.508417  6.325217    6.383069      54500.0   \n",
       "5391759          1.0   6.383069   6.450564  6.325217    6.325217      21000.0   \n",
       "\n",
       "         Daily Variation  Percentage Variation  Adj. Daily Variation  \\\n",
       "5391755             3.24             58.909091              3.124040   \n",
       "5391756             0.44              6.646526              0.424252   \n",
       "5391757             0.44              6.367583              0.424252   \n",
       "5391758             0.19              2.896341              0.183200   \n",
       "5391759             0.13              1.963746              0.125347   \n",
       "\n",
       "         Adj. Percentage Variation  \n",
       "5391755                  58.909091  \n",
       "5391756                   6.646526  \n",
       "5391757                   6.367583  \n",
       "5391758                   2.896341  \n",
       "5391759                   1.963746  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract GAIA data\n",
    "gaia = df[df['Symbol'] == 'GAIA']\n",
    "gaia.head()\n",
    "# GAIA data is available from 1999-10-29 to 2016-09-09."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Adj. Volume</th>\n",
       "      <th>Daily Variation</th>\n",
       "      <th>Percentage Variation</th>\n",
       "      <th>Adj. Daily Variation</th>\n",
       "      <th>Adj. Percentage Variation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1928868</th>\n",
       "      <td>BP</td>\n",
       "      <td>1999-10-29</td>\n",
       "      <td>57.5</td>\n",
       "      <td>58.12</td>\n",
       "      <td>57.38</td>\n",
       "      <td>57.75</td>\n",
       "      <td>2688800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.106849</td>\n",
       "      <td>28.409914</td>\n",
       "      <td>28.048192</td>\n",
       "      <td>28.229053</td>\n",
       "      <td>2688800.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.286957</td>\n",
       "      <td>0.361723</td>\n",
       "      <td>1.286957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbol        Date  Open   High    Low  Close     Volume  Ex-Dividend  \\\n",
       "1928868     BP  1999-10-29  57.5  58.12  57.38  57.75  2688800.0          0.0   \n",
       "\n",
       "         Split Ratio  Adj. Open  Adj. High   Adj. Low  Adj. Close  \\\n",
       "1928868          1.0  28.106849  28.409914  28.048192   28.229053   \n",
       "\n",
       "         Adj. Volume  Daily Variation  Percentage Variation  \\\n",
       "1928868    2688800.0             0.74              1.286957   \n",
       "\n",
       "         Adj. Daily Variation  Adj. Percentage Variation  \n",
       "1928868              0.361723                   1.286957  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check index of row where BP and GAIA data start intersecting \n",
    "# i.e. date = 1999-10-29\n",
    "bp.loc[bp['Date'] == '1999-10-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessica/anaconda/envs/python2.7/lib/python2.7/site-packages/pandas/core/indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/jessica/anaconda/envs/python2.7/lib/python2.7/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# Add GAIA figures to BP dataframe\n",
    "\n",
    "# GAIA data starts on 1999-10-29\n",
    "\n",
    "# Label for the BP row with date 1999-10-29\n",
    "bp_gaia_start = 1928868\n",
    "# Label for the GAIA row with date 1999-10-29\n",
    "gaia_start = 5391755\n",
    "\n",
    "data_to_copy = ['Date', 'Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close']\n",
    "\n",
    "bp_gaia_intersect_length = 3753\n",
    "\n",
    "for i in range(bp_gaia_intersect_length):\n",
    "    for col in data_to_copy:\n",
    "        bp.loc[bp_gaia_start+i,'GAIA %s' % str(col)] = gaia.loc[gaia_start+i,'%s' % str(col)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2.3 FTSE 100:\n",
    "\n",
    "Source: Scraped from Google Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-09</td>\n",
       "      <td>6858.70</td>\n",
       "      <td>6862.38</td>\n",
       "      <td>6762.30</td>\n",
       "      <td>6776.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>6846.58</td>\n",
       "      <td>6889.64</td>\n",
       "      <td>6819.82</td>\n",
       "      <td>6858.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>6826.05</td>\n",
       "      <td>6856.12</td>\n",
       "      <td>6814.87</td>\n",
       "      <td>6846.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-06</td>\n",
       "      <td>6879.42</td>\n",
       "      <td>6887.92</td>\n",
       "      <td>6818.96</td>\n",
       "      <td>6826.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>6894.60</td>\n",
       "      <td>6910.66</td>\n",
       "      <td>6867.08</td>\n",
       "      <td>6879.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Open     High      Low    Close\n",
       "0  2016-09-09  6858.70  6862.38  6762.30  6776.95\n",
       "1  2016-09-08  6846.58  6889.64  6819.82  6858.70\n",
       "2  2016-09-07  6826.05  6856.12  6814.87  6846.58\n",
       "3  2016-09-06  6879.42  6887.92  6818.96  6826.05\n",
       "4  2016-09-05  6894.60  6910.66  6867.08  6879.42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in FTSE100 data\n",
    "ftse100_csv = pd.read_csv(\"ftse100-figures.csv\")\n",
    "\n",
    "# Preview data\n",
    "ftse100_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8187</th>\n",
       "      <td>1984-04-02</td>\n",
       "      <td>1108.1</td>\n",
       "      <td>1108.1</td>\n",
       "      <td>1108.1</td>\n",
       "      <td>1108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8186</th>\n",
       "      <td>1984-04-03</td>\n",
       "      <td>1095.4</td>\n",
       "      <td>1095.4</td>\n",
       "      <td>1095.4</td>\n",
       "      <td>1095.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8185</th>\n",
       "      <td>1984-04-04</td>\n",
       "      <td>1095.4</td>\n",
       "      <td>1095.4</td>\n",
       "      <td>1095.4</td>\n",
       "      <td>1095.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184</th>\n",
       "      <td>1984-04-05</td>\n",
       "      <td>1102.2</td>\n",
       "      <td>1102.2</td>\n",
       "      <td>1102.2</td>\n",
       "      <td>1102.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8183</th>\n",
       "      <td>1984-04-06</td>\n",
       "      <td>1096.3</td>\n",
       "      <td>1096.3</td>\n",
       "      <td>1096.3</td>\n",
       "      <td>1096.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close\n",
       "8187  1984-04-02  1108.1  1108.1  1108.1  1108.1\n",
       "8186  1984-04-03  1095.4  1095.4  1095.4  1095.4\n",
       "8185  1984-04-04  1095.4  1095.4  1095.4  1095.4\n",
       "8184  1984-04-05  1102.2  1102.2  1102.2  1102.2\n",
       "8183  1984-04-06  1096.3  1096.3  1096.3  1096.3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort FTSE100 data by date (ascending) to fit with LSE stock data\n",
    "\n",
    "# Date range from 1984-04-02 to 2016-09-09\n",
    "sorted_ftse100 = ftse100_csv.sort_values(by='Date')\n",
    "sorted_ftse100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>...</th>\n",
       "      <th>Adj. Volume</th>\n",
       "      <th>Daily Variation</th>\n",
       "      <th>Percentage Variation</th>\n",
       "      <th>Adj. Daily Variation</th>\n",
       "      <th>Adj. Percentage Variation</th>\n",
       "      <th>GAIA Date</th>\n",
       "      <th>GAIA Adj. Open</th>\n",
       "      <th>GAIA Adj. High</th>\n",
       "      <th>GAIA Adj. Low</th>\n",
       "      <th>GAIA Adj. Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1924931</th>\n",
       "      <td>BP</td>\n",
       "      <td>1984-04-02</td>\n",
       "      <td>45.62</td>\n",
       "      <td>46.38</td>\n",
       "      <td>45.5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>209700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.748742</td>\n",
       "      <td>...</td>\n",
       "      <td>838800.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.928979</td>\n",
       "      <td>0.091602</td>\n",
       "      <td>1.928979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbol        Date   Open   High   Low  Close    Volume  Ex-Dividend  \\\n",
       "1924931     BP  1984-04-02  45.62  46.38  45.5   46.0  209700.0          0.0   \n",
       "\n",
       "         Split Ratio  Adj. Open       ...         Adj. Volume  \\\n",
       "1924931          1.0   4.748742       ...            838800.0   \n",
       "\n",
       "         Daily Variation  Percentage Variation  Adj. Daily Variation  \\\n",
       "1924931             0.88              1.928979              0.091602   \n",
       "\n",
       "         Adj. Percentage Variation  GAIA Date  GAIA Adj. Open  GAIA Adj. High  \\\n",
       "1924931                   1.928979        NaN             NaN             NaN   \n",
       "\n",
       "        GAIA Adj. Low  GAIA Adj. Close  \n",
       "1924931           NaN              NaN  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check index of row where BP and FTSE data start intersecting \n",
    "# i.e. date = 1984-04-02\n",
    "bp[bp['Date'] == '1984-04-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adds FTSE data to BP dataframe, joining at dates\n",
    "\n",
    "# FTSE columns we want to copy to BP dataframe\n",
    "ftse_data_to_copy = ['Date', 'Open', 'High', 'Low', 'Close']    \n",
    "\n",
    "# FTSE data starts on 1984-04-02\n",
    "\n",
    "# Label for the BP row with date 1984-04-02\n",
    "bp_ftse_start = 1924931\n",
    "# Label for the FTSE row with date 1984-04-02\n",
    "ftse_start = 8187\n",
    "\n",
    "bp_counter = 0\n",
    "ftse_counter = 0\n",
    "while ftse_counter < len(sorted_ftse100):\n",
    "    bp_date = bp.loc[bp_ftse_start + bp_counter, 'Date']\n",
    "    ftse_date = sorted_ftse100.loc[ftse_start - ftse_counter, 'Date']\n",
    "    if bp_date == ftse_date:\n",
    "        # Add FTSE data to BP row\n",
    "        for col in ftse_data_to_copy:\n",
    "            bp.loc[bp_ftse_start + bp_counter, 'FTSE %s' % str(col)] = sorted_ftse100.loc[ftse_start - ftse_counter,'%s' % str(col)]\n",
    "        # FTSE counter + 1, BP counter + 1\n",
    "        bp_counter += 1\n",
    "        ftse_counter += 1\n",
    "    elif bp_date < ftse_date:\n",
    "        # Move to next BP row, same FTSE row and repeat\n",
    "        bp_counter += 1\n",
    "    elif bp_date > ftse_date:\n",
    "        # Move to next FTSE row, same BP row and repeat\n",
    "        ftse_counter += 1\n",
    "    else:\n",
    "        print \"Error: BP date is \", bp_date, \"; FTSE date is \", ftse_date\n",
    "        # FTSE row + 1, BP row + 1\n",
    "        bp_counter += 1\n",
    "        ftse_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984-04-27\n",
      "1984-05-02\n",
      "1984-05-07\n",
      "1984-05-29\n",
      "1984-08-27\n",
      "1984-12-26\n",
      "1985-04-08\n",
      "1985-05-06\n",
      "1985-08-26\n",
      "1985-12-26\n",
      "1986-03-31\n",
      "1986-05-05\n",
      "1986-08-25\n",
      "1986-12-26\n",
      "1987-04-20\n",
      "1987-05-04\n",
      "1987-08-31\n",
      "1987-12-28\n",
      "1988-04-04\n",
      "1988-05-02\n",
      "1988-08-29\n",
      "1988-12-27\n",
      "1989-03-27\n",
      "1989-05-01\n",
      "1989-08-28\n",
      "1989-12-26\n",
      "1990-04-16\n",
      "1990-05-07\n",
      "1990-08-27\n",
      "1990-12-26\n",
      "1991-04-01\n",
      "1991-05-06\n",
      "1991-08-26\n",
      "1991-12-26\n",
      "1992-04-20\n",
      "1992-05-04\n",
      "1992-08-31\n",
      "1992-12-28\n",
      "1993-04-12\n",
      "1993-05-03\n",
      "1993-08-30\n",
      "1993-12-27\n",
      "1993-12-28\n",
      "1994-01-03\n",
      "1994-04-04\n",
      "1994-05-02\n",
      "1994-08-29\n",
      "1994-12-27\n",
      "1995-04-17\n",
      "1995-05-08\n",
      "1995-08-28\n",
      "1995-12-26\n",
      "1996-04-08\n",
      "1996-05-06\n",
      "1996-08-26\n",
      "1996-12-26\n",
      "1997-03-31\n",
      "1997-05-05\n",
      "1997-08-25\n",
      "1997-12-26\n",
      "1998-04-13\n",
      "1998-05-04\n",
      "1998-08-31\n",
      "1998-12-28\n",
      "1998-12-31\n",
      "1999-04-05\n",
      "1999-05-03\n",
      "1999-08-30\n",
      "1999-12-27\n",
      "1999-12-28\n",
      "1999-12-31\n",
      "2000-01-03\n",
      "2000-04-24\n",
      "2000-05-01\n",
      "2000-08-28\n",
      "2000-12-26\n",
      "2001-04-16\n",
      "2001-05-07\n",
      "2001-08-27\n",
      "2001-12-26\n",
      "2002-04-01\n",
      "2002-05-06\n",
      "2002-06-03\n",
      "2002-06-04\n",
      "2002-08-26\n",
      "2002-12-26\n",
      "2003-04-21\n",
      "2003-05-05\n",
      "2003-08-25\n",
      "2003-12-26\n",
      "2004-04-12\n",
      "2004-05-03\n",
      "2004-08-30\n",
      "2004-12-27\n",
      "2004-12-28\n",
      "2005-01-03\n",
      "2005-03-28\n",
      "2005-05-02\n",
      "2005-08-29\n",
      "2005-12-27\n",
      "2006-04-17\n",
      "2006-05-01\n",
      "2006-08-28\n",
      "2006-12-26\n",
      "2007-04-09\n",
      "2007-05-07\n",
      "2007-08-27\n",
      "2007-12-26\n",
      "2008-03-24\n",
      "2008-05-05\n",
      "2008-08-25\n",
      "2008-12-26\n",
      "2009-03-27\n",
      "2009-04-13\n",
      "2009-05-04\n",
      "2009-06-25\n",
      "2009-08-11\n",
      "2009-08-31\n",
      "2009-09-02\n",
      "2009-12-28\n",
      "2010-04-05\n",
      "2010-04-19\n",
      "2010-04-20\n",
      "2010-05-03\n",
      "2010-05-12\n",
      "2010-08-30\n",
      "2010-12-27\n",
      "2010-12-28\n",
      "2011-01-03\n",
      "2011-04-25\n",
      "2011-04-29\n",
      "2011-05-02\n",
      "2011-08-29\n",
      "2011-12-27\n",
      "2012-04-09\n",
      "2012-05-07\n",
      "2012-06-04\n",
      "2012-06-05\n",
      "2012-08-27\n",
      "2012-12-26\n",
      "2013-04-01\n",
      "2013-05-06\n",
      "2013-08-26\n",
      "2013-09-23\n",
      "2013-12-26\n",
      "2014-04-21\n",
      "2014-05-05\n",
      "2014-08-25\n",
      "2014-12-26\n",
      "2015-01-02\n",
      "2015-04-06\n",
      "2015-05-04\n",
      "2015-08-31\n",
      "2015-12-17\n",
      "2015-12-28\n",
      "2016-03-28\n",
      "2016-05-02\n",
      "2016-08-29\n",
      "NaNs:  158\n"
     ]
    }
   ],
   "source": [
    "# Count and display NaNs in FTSE data \n",
    "# i.e. dates where we have BP but not FTSE data\n",
    "nan_counter = 0\n",
    "for row in range(len(bp.loc[bp_ftse_start:])):\n",
    "    if pd.isnull(bp.loc[bp_ftse_start+row, 'FTSE Date']):\n",
    "        print bp.loc[bp_ftse_start+row, 'Date']\n",
    "        nan_counter += 1\n",
    "print \"NaNs: \", nan_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proxy remaining FTSE NaNs by taking the mean of the prices in the \n",
    "# two closest trading days where data is available \n",
    "# (one before, one after the day)\n",
    "ftse_data_to_average = ['Open', 'High', 'Low', 'Close']    \n",
    "for row in range(len(bp.loc[bp_ftse_start:])):\n",
    "    if pd.isnull(bp.loc[bp_ftse_start+row, 'FTSE Date']):\n",
    "        if not (pd.isnull(bp.loc[bp_ftse_start+row-1, 'FTSE Date']) or pd.isnull(bp.loc[bp_ftse_start+row+1, 'FTSE Date'])):\n",
    "            for col in ftse_data_to_average:\n",
    "                bp.loc[bp_ftse_start+row,'FTSE %s' % str(col)] = np.mean([float(bp.loc[bp_ftse_start+row-1,'FTSE %s' % str(col)]), float(bp.loc[bp_ftse_start+row+1,'FTSE %s' % str(col)])])\n",
    "            bp.loc[bp_ftse_start+row,'FTSE Date'] = bp.loc[bp_ftse_start+row, 'Date']\n",
    "        else:\n",
    "            go_back = 0\n",
    "            go_forward = 0\n",
    "            while pd.isnull(bp.loc[bp_ftse_start+row-1-go_back, 'FTSE Date']):\n",
    "                go_back += 1\n",
    "            while pd.isnull(bp.loc[bp_ftse_start+row+1+go_forward, 'FTSE Date']):\n",
    "                go_forward += 1\n",
    "            for col in ftse_data_to_average:\n",
    "                    bp.loc[bp_ftse_start+row,'FTSE %s' % str(col)] = np.mean([float(bp.loc[bp_ftse_start+row-1-go_back,'FTSE %s' % str(col)]), float(bp.loc[bp_ftse_start+row+1+go_forward,'FTSE %s' % str(col)])])\n",
    "            bp.loc[bp_ftse_start+row,'FTSE Date'] = bp.loc[bp_ftse_start+row, 'Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs:  0\n"
     ]
    }
   ],
   "source": [
    "# Check there are no more NaNs\n",
    "nan_counter = 0\n",
    "for row in range(len(bp.loc[bp_ftse_start:])):\n",
    "    if pd.isnull(bp.loc[bp_ftse_start+row, 'FTSE Date']):\n",
    "        print bp.loc[bp_ftse_start+row, 'Date']\n",
    "        nan_counter += 1\n",
    "print \"NaNs: \", nan_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Build training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_train_test(days, periods, target='Adj. Close', test_size=0.2, buffer=0, target_days=7):  \n",
    "    \"\"\"Returns X_train, X_test, y_train, y_test for parameters.\n",
    "    Predicts prices `target_days` ahead.\n",
    "    `days` = number of days prior we consider\"\"\"\n",
    "    # Columns\n",
    "    columns = []\n",
    "    for j in range(1,days+1):\n",
    "        columns.append('i-%s' % str(j))\n",
    "    columns.append('Adj. High')\n",
    "    columns.append('Adj. Low')\n",
    "\n",
    "    # Columns: Prices (predict multiple day)\n",
    "    nday_columns = []\n",
    "    for j in range(1,target_days+1):\n",
    "        nday_columns.append('Day %s' % str(j-1))\n",
    "\n",
    "    # Index\n",
    "    start_date = bp.iloc[days+buffer][\"Date\"]\n",
    "    index = pd.date_range(start_date, periods=periods, freq='D')\n",
    "\n",
    "    # Create empty dataframes for features and prices\n",
    "    features = pd.DataFrame(index=index, columns=columns)\n",
    "    prices = pd.DataFrame(index=index, columns=[\"Target\"])\n",
    "    nday_prices = pd.DataFrame(index=index, columns=nday_columns)\n",
    "\n",
    "    # Prepare test and training sets\n",
    "    for i in range(periods):\n",
    "        # Fill in Target df\n",
    "        for j in range(target_days):\n",
    "            nday_prices.iloc[i]['Day %s' % str(j)] = bp.iloc[buffer+i+days+j][target]\n",
    "        # Fill in Features df\n",
    "        for j in range(days):\n",
    "            features.iloc[i]['i-%s' % str(days-j)] = bp.iloc[buffer+i+j][target]\n",
    "        features.iloc[i]['Adj. High'] = max(bp[buffer+i:buffer+i+days]['Adj. High'])\n",
    "        features.iloc[i]['Adj. Low'] = min(bp[buffer+i:buffer+i+days]['Adj. Low'])\n",
    "                \n",
    "    X = features\n",
    "    y = nday_prices\n",
    "    print \"X.tail: \", X.tail()\n",
    "\n",
    "    # Train-test split\n",
    "    if len(X) != len(y):\n",
    "        return \"Error\"\n",
    "    split_index = int(len(X) * (1-test_size))\n",
    "    X_train = X[:split_index]\n",
    "    X_test = X[split_index:]\n",
    "    y_train = y[:split_index]\n",
    "    y_test = y[split_index:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialise variables to prevent errors\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named multioutput",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8a196c069a0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import MultiOutputRegressor to handle predicting multiple outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultioutput\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiOutputRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Import metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named multioutput"
     ]
    }
   ],
   "source": [
    "# Import MultiOutputRegressor to handle predicting multiple outputs\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions for metrics\n",
    "def rmsp(test, pred):\n",
    "    return np.sqrt(np.mean(((test - pred)/test)**2)) * 100\n",
    "\n",
    "def print_metrics(test, pred):\n",
    "    print \"Root Mean Squared Percentage Error\", rmsp(test, pred)\n",
    "    print \"Mean Absolute Error: \", mean_absolute_error(test, pred)\n",
    "    print \"Explained Variance Score: \", explained_variance_score(test, pred)\n",
    "    print \"Mean Squared Error: \", mean_squared_error(test, pred)\n",
    "    print \"R2 score: \", r2_score(test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Classifiers\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialise variables to prevent errors\n",
    "days = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply Classifier and Print Metrics\n",
    "def classify_and_metrics(clf=LinearRegression(), target_days=7, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, days=days):\n",
    "    \"\"\"Trains and tests classifier on training and test datasets.\n",
    "    Prints performance metrics.\n",
    "    \"\"\"\n",
    "    # Classify and predict\n",
    "    clf = MultiOutputRegressor(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    # Lines below for debugging purposes\n",
    "#    print \"X_train.head(): \", X_train.head()\n",
    "#    print \"X_train.tail(): \", X_train.tail()\n",
    "#    print \"Pred: \", pred[:5]\n",
    "#    print \"Test: \", y_test[:5]\n",
    "    \n",
    "    # Print metrics\n",
    "    print \"# Days used to predict: %s\" % str(days)\n",
    "    print \"\\n%s-day predictions\" % str(target_days) \n",
    "    print_metrics(y_test, pred)\n",
    "    return rmsp(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do multiple train-test cycles on different train-test sets and see\n",
    "# if they all produce reliable results\n",
    "def execute(steps=8, buffer_step=1000, days=7, periods=1000, model=LinearRegression(), predict_days=7):\n",
    "    \"\"\"Performs `steps` train-test cycles and prints evaluation metrics for BP data.\n",
    "    `steps`: number of train-test cycles.\n",
    "    `periods`: the total number of datapoints used in each cycle (training + test)\n",
    "    `buffer_step`: number of datapoints between the starting points of each\n",
    "    consecutive train-test cycle\n",
    "    \"\"\"\n",
    "    errors=[]\n",
    "    r2=[]\n",
    "    for segment in range(steps):\n",
    "        buffer = segment*buffer_step\n",
    "        print \"Buffer: \", buffer\n",
    "        X_train, X_test, y_train, y_test = prepare_train_test(days=days, periods=periods, buffer=buffer)\n",
    "        errors.append(classify_and_metrics(clf=model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, days=days))\n",
    "    print \"Errors: \", errors\n",
    "    \n",
    "    daily_error = []\n",
    "    for target_day in range(predict_days):\n",
    "        daily_error.append([])\n",
    "    for segment in range(steps):\n",
    "        for target_day in range(predict_days):\n",
    "            daily_error[target_day].append(errors[segment][target_day])\n",
    "    print \"Daily error: \", daily_error\n",
    "    average_daily_error = []\n",
    "    for day in daily_error:\n",
    "        average_daily_error.append(np.mean(day))\n",
    "    print \"Mean daily error: \", average_daily_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# svm.SVR() trial\n",
    "execute(model=svm.SVR(), steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression trial\n",
    "execute(steps=8)\n",
    "\n",
    "# R2 scores: [0.859, 0.791, 0.606, 0.936, 0.835, 0.871, 0.623, 0.936]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Refinement\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Tuning model parameters\n",
    "\n",
    "No change in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Adding more of the same type of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Considering more than 7 days' worth of prior data\n",
    "# 10 days' worth of prior data\n",
    "execute(steps=10, days=10, buffer_step = 700)\n",
    "\n",
    "# Mean daily error:  [1.7321477061307597, 2.5432152188018913, 3.1383346165356416, 3.5793927574194155, 3.9394427230724309, 4.2692644737508925, 4.5432050435026108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consider 14 days' worth of prior data\n",
    "execute(steps=15, days=14, buffer_step = 500)\n",
    "\n",
    "# Mean daily error:  [1.7285404855953252, 2.5255007498628097, 3.1026280963920607, 3.5862999911658147, 4.0020669863612239, 4.3722863441980762, 4.701971393685997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consider 21 days' worth of prior data\n",
    "execute(steps=15, days=21, buffer_step = 500)\n",
    "\n",
    "# Mean daily error:  [1.7458324393865607, 2.5550697635040556, 3.1130306876040765, 3.5859111257648624, 3.9906346379964006, 4.3416348748811986, 4.6578080578960108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consider 30 days' worth of prior data\n",
    "\n",
    "execute(steps=15, days=30, buffer_step = 500)\n",
    "\n",
    "# Mean daily error:  [1.7839163888017815, 2.593162562286222, 3.1521417303676622, 3.6325948299484372, 4.0479378120671301, 4.3916975345657692, 4.7046907424412074]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consider 100 days' worth of prior data\n",
    "\n",
    "execute(steps=15, days=100, buffer_step = 500)\n",
    "\n",
    "# Mean daily error:  [1.9238550915564432, 2.7676076433106056, 3.3695076303415705, 3.8902423145616098, 4.3550552824867319, 4.7687380251335467, 5.1629268283684322]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Adding Oil Stock Prices (GAIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dataframe with BP and GAIA data in overlapping date range\n",
    "# Date range: 1999-10-29 to 2014-09-30\n",
    "# `bp_gaia_start` etc defined in Feature Engineering section 1.2.2.2\n",
    "bp_gaia = bp.loc[bp_gaia_start:bp_gaia_start+bp_gaia_intersect_length-1]\n",
    "\n",
    "# Check it ends at the right date\n",
    "bp_gaia.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(bp_gaia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify `prepare_train_test` function to add GAIA data.\n",
    "\n",
    "# Potential improvement: Generalise `prepare_train_test` function instead\n",
    "# of copy and pasting it and making a new function.\n",
    "def prepare_train_test_with_gaia(days, periods, target='Adj. Close', test_size=0.2, buffer=0, target_days=7, df=bp_gaia):  \n",
    "    \"\"\"Returns X_train, X_test, y_train, y_test for parameters.\n",
    "    Predicts prices `target_days` ahead.\n",
    "    `days`: the number of days prior we consider (the prices of)\n",
    "    `periods`: the total number of datapoints used (training + test)\n",
    "    \"\"\"\n",
    "    # Columns\n",
    "    # BP cols\n",
    "    columns = []\n",
    "    for j in range(1,days+1):\n",
    "        columns.append('i-%s' % str(j))\n",
    "    columns.append('Adj. High')\n",
    "    columns.append('Adj. Low')\n",
    "    # GAIA cols\n",
    "    for j in range(1,days+1):\n",
    "        columns.append('GAIA i-%s' % str(j))\n",
    "    columns.append('GAIA Adj. High')\n",
    "    columns.append('GAIA Adj. Low')\n",
    "\n",
    "    # Columns: Prices (predict multiple day)\n",
    "    nday_columns = []\n",
    "    for j in range(1,target_days+1):\n",
    "        nday_columns.append('Day %s' % str(j-1))\n",
    "\n",
    "    # Index\n",
    "    start_date = df.iloc[days+buffer][\"Date\"]\n",
    "    index = pd.date_range(start_date, periods=periods, freq='D')\n",
    "\n",
    "    # Create empty dataframes for features and prices\n",
    "    features = pd.DataFrame(index=index, columns=columns)\n",
    "    prices = pd.DataFrame(index=index, columns=[\"Target\"])\n",
    "    nday_prices = pd.DataFrame(index=index, columns=nday_columns)\n",
    "\n",
    "    # Prepare test and training sets\n",
    "    for i in range(periods):\n",
    "        # Fill in Target df\n",
    "        for j in range(target_days):\n",
    "            nday_prices.iloc[i]['Day %s' % str(j)] = df.iloc[buffer+i+days+j][target]\n",
    "        # Fill in Features df\n",
    "        for j in range(days):\n",
    "            features.iloc[i]['i-%s' % str(days-j)] = df.iloc[buffer+i+j][target]\n",
    "        features.iloc[i]['Adj. High'] = max(df[buffer+i:buffer+i+days]['Adj. High'])\n",
    "        features.iloc[i]['Adj. Low'] = min(df[buffer+i:buffer+i+days]['Adj. Low'])\n",
    "        for j in range(days):\n",
    "            features.iloc[i]['GAIA i-%s' % str(days-j)] = df.iloc[buffer+i+j]['GAIA %s' % str(target)]\n",
    "        features.iloc[i]['GAIA Adj. High'] = max(df[buffer+i:buffer+i+days]['GAIA Adj. High'])\n",
    "        features.iloc[i]['GAIA Adj. Low'] = min(df[buffer+i:buffer+i+days]['GAIA Adj. Low'])\n",
    "                \n",
    "    X = features\n",
    "    y = nday_prices\n",
    "\n",
    "    # Train-test split\n",
    "    if len(X) != len(y):\n",
    "        return \"Error\"\n",
    "    split_index = int(len(X) * (1-test_size))\n",
    "    X_train = X[:split_index]\n",
    "    X_test = X[split_index:]\n",
    "    y_train = y[:split_index]\n",
    "    y_test = y[split_index:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_with_gaia(steps=8, buffer_step=200, days=7, periods=1000, model=LinearRegression(), predict_days=7):\n",
    "    \"\"\"Performs `steps` train-test cycles and prints evaluation metrics for BP + GAIA data.\n",
    "    `steps`: number of train-test cycles.\n",
    "    `periods`: the total number of datapoints used in each cycle (training + test)\n",
    "    `buffer_step`: number of datapoints between the starting points of each\n",
    "    consecutive train-test cycle\n",
    "    \"\"\"\n",
    "    errors=[]\n",
    "    r2=[]\n",
    "    for segment in range(steps):\n",
    "        buffer = segment*buffer_step\n",
    "        print \"Buffer: \", buffer\n",
    "        X_train, X_test, y_train, y_test = prepare_train_test_with_gaia(days=days, periods=periods, buffer=buffer, df=bp_gaia)\n",
    "        errors.append(classify_and_metrics(clf=model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, days=days))\n",
    "    print \"Errors: \", errors\n",
    "    \n",
    "    daily_error = []\n",
    "    for target_day in range(predict_days):\n",
    "        daily_error.append([])\n",
    "    for segment in range(steps):\n",
    "        for target_day in range(predict_days):\n",
    "            daily_error[target_day].append(errors[segment][target_day])\n",
    "    print \"Daily error: \", daily_error\n",
    "    average_daily_error = []\n",
    "    for day in daily_error:\n",
    "        average_daily_error.append(np.mean(day))\n",
    "    print \"Mean daily error: \", average_daily_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consider 7 days' worth of BP and GAIA data\n",
    "execute_with_gaia(steps=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consider 10 days' worth of BP and GAIA data\n",
    "execute_with_gaia(days=10, steps=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 TODO: Adding FTSE100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create df with BP and FTSE data\n",
    "bp_ftse = bp.loc[bp_ftse_start:]\n",
    "bp_ftse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modify `prepare_train_test` function to add FTSE data.\n",
    "def prepare_train_test_with_ftse(days, periods, target='Adj. Close', test_size=0.2, buffer=0, target_days=7, df=bp_ftse, name='FTSE'):  \n",
    "    \"\"\"Returns X_train, X_test, y_train, y_test for parameters.\n",
    "    Predicts prices `target_days` ahead.\n",
    "    `days` = number of days prior we consider\"\"\"\n",
    "    # Columns\n",
    "    # BP cols\n",
    "    columns = []\n",
    "    for j in range(1,days+1):\n",
    "        columns.append('i-%s' % str(j))\n",
    "    columns.append('Adj. High')\n",
    "    columns.append('Adj. Low')\n",
    "    # FTSE cols\n",
    "    for j in range(1,days+1):\n",
    "        columns.append('%s i-%s' % (name, str(j)))\n",
    "    columns.append('%s High' % name)\n",
    "    columns.append('%s Low' % name)\n",
    "\n",
    "    # Columns: Prices (predict multiple day)\n",
    "    nday_columns = []\n",
    "    for j in range(1,target_days+1):\n",
    "        nday_columns.append('Day %s' % str(j-1))\n",
    "\n",
    "    # Index\n",
    "    start_date = df.iloc[days+buffer][\"Date\"]\n",
    "    index = pd.date_range(start_date, periods=periods, freq='D')\n",
    "\n",
    "    # Create empty dataframes for features and prices\n",
    "    features = pd.DataFrame(index=index, columns=columns)\n",
    "    prices = pd.DataFrame(index=index, columns=[\"Target\"])\n",
    "    nday_prices = pd.DataFrame(index=index, columns=nday_columns)\n",
    "\n",
    "    # Prepare test and training sets\n",
    "    for i in range(periods):\n",
    "        # Fill in Target df\n",
    "        for j in range(target_days):\n",
    "            nday_prices.iloc[i]['Day %s' % str(j)] = df.iloc[buffer+i+days+j][target]\n",
    "        # Fill in Features df\n",
    "        for j in range(days):\n",
    "            features.iloc[i]['i-%s' % str(days-j)] = df.iloc[buffer+i+j][target]\n",
    "        features.iloc[i]['Adj. High'] = max(df[buffer+i:buffer+i+days]['Adj. High'])\n",
    "        features.iloc[i]['Adj. Low'] = min(df[buffer+i:buffer+i+days]['Adj. Low'])\n",
    "        for j in range(days):\n",
    "            features.iloc[i]['%s i-%s' % (name, str(days-j))] = df.iloc[buffer+i+j]['%s %s' % (name, 'Close')]\n",
    "        features.iloc[i]['%s High' % name] = max(df[buffer+i:buffer+i+days]['%s High' % name])\n",
    "        features.iloc[i]['%s Low' % name] = min(df[buffer+i:buffer+i+days]['%s Low' % name])\n",
    "                \n",
    "    X = features\n",
    "    y = nday_prices\n",
    "\n",
    "    # Train-test split\n",
    "    if len(X) != len(y):\n",
    "        return \"Error\"\n",
    "    split_index = int(len(X) * (1-test_size))\n",
    "    X_train = X[:split_index]\n",
    "    X_test = X[split_index:]\n",
    "    y_train = y[:split_index]\n",
    "    y_test = y[split_index:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_with_ftse(steps=8, buffer_step=200, days=7, periods=1000, model=LinearRegression(), predict_days=7):\n",
    "    \"\"\"Performs `steps` train-test cycles and prints evaluation metrics for BP + FTSE data.\n",
    "    `steps`: number of train-test cycles.\n",
    "    `periods`: the total number of datapoints used in each cycle (training + test)\n",
    "    `buffer_step`: number of datapoints between the starting points of each\n",
    "    consecutive train-test cycle\n",
    "    \"\"\"\n",
    "    errors=[]\n",
    "    r2=[]\n",
    "    for segment in range(steps):\n",
    "        buffer = segment*buffer_step\n",
    "        print \"Buffer: \", buffer\n",
    "        X_train, X_test, y_train, y_test = prepare_train_test_with_ftse(days=days, periods=periods, buffer=buffer, df=bp_ftse)\n",
    "        errors.append(classify_and_metrics(clf=model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, days=days))\n",
    "    print \"Errors: \", errors\n",
    "    \n",
    "    daily_error = []\n",
    "    for target_day in range(predict_days):\n",
    "        daily_error.append([])\n",
    "    for segment in range(steps):\n",
    "        for target_day in range(predict_days):\n",
    "            daily_error[target_day].append(errors[segment][target_day])\n",
    "    print \"Daily error: \", daily_error\n",
    "    average_daily_error = []\n",
    "    for day in daily_error:\n",
    "        average_daily_error.append(np.mean(day))\n",
    "    print \"Mean daily error: \", average_daily_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Consider 7 days' worth of prior BP and FTSE data\n",
    "execute_with_ftse(days=7, steps=15, buffer_step=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consider 10 days' worth of prior BP and FTSE data\n",
    "execute_with_ftse(days=10, steps=15, buffer_step=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: Free-Form Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We want an array with predictions for our model in a long date range.\n",
    "# We will consider the max error predictions, that is,\n",
    "# predictions of adjusted close prices 7 days ahead.\n",
    "\n",
    "# Initialise variable\n",
    "predictions_800_off = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(clf=LinearRegression(), target_days=7, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, days=days):\n",
    "    \"\"\"Trains and tests classifier on training and test datasets.\n",
    "    Append predictions to `predictions_800_off`.\n",
    "    \"\"\"\n",
    "    # Classify and predict\n",
    "    clf = MultiOutputRegressor(clf)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    print \"Pred: \", pred\n",
    "    predictions_800_off.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pared-down execute function that runs train-test cycles and \n",
    "# appends the predictions to `predictions_800_off` via the function `predict()`.\n",
    "def execute_viz(steps=8, buffer_step=200, days=7, periods=1000, model=LinearRegression(), predict_days=7):\n",
    "    \"\"\"Performs `steps` train-test cycles and prints evaluation metrics for BP + FTSE data.\n",
    "    `steps`: number of train-test cycles.\n",
    "    `periods`: the total number of datapoints used in each cycle (training + test)\n",
    "    `buffer_step`: number of datapoints between the starting points of each\n",
    "    consecutive train-test cycle\n",
    "    \"\"\"\n",
    "    for segment in range(steps):\n",
    "        buffer = segment*buffer_step\n",
    "        print \"Buffer: \", buffer\n",
    "        X_train, X_test, y_train, y_test = prepare_train_test_with_ftse(days=days, periods=periods, buffer=buffer, df=bp_ftse)\n",
    "        predict(clf=model, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, days=days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract predictions. \n",
    "# `execute_viz` function appends predictions to `predictions_800_off`.\n",
    "execute_viz(steps=35)\n",
    "predictions_800_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Put all 7-days-ahead predictions into an array\n",
    "predictions_800_7thday = []\n",
    "for array in predictions_800_off:\n",
    "    for week_prediction in array:\n",
    "        predictions_800_7thday.append(week_prediction[6]) \n",
    "print len(predictions_800_7thday)\n",
    "predictions_800_7thday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare dataframe for visualisation\n",
    "# There are 7000 predictions\n",
    "bp_final_predictions = bp_ftse[800+6:806+7000]\n",
    "bp_final_predictions.loc[:,'7d Ahead Pred'] = predictions_800_7thday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting predictions compared with actual adjusted close prices\n",
    "bp_final_predictions.plot(y=['Adj. Close','7d Ahead Pred'], x='Date').set_title(\"Model Predictions against BP Actual Adjusted Close Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting predictions compared with actual prices\n",
    "# Only first 200 predictions\n",
    "bp_preds_200 = bp_final_predictions[:200]\n",
    "bp_preds_200.plot(y=['Adj. Close','7d Ahead Pred'], x='Date', y='Price (Â£)').set_title(\"Model Predictions against BP Actual Adjusted Close Prices\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python2.7]",
   "language": "python",
   "name": "Python [python2.7]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
